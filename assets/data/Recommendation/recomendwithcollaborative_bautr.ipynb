{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc92e2427818993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T09:02:47.405834Z",
     "start_time": "2024-05-18T09:02:07.270234Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0, Loss: 1.0083401203155518\n",
      "Epoch 2, Step 0, Loss: 0.9972688555717468\n",
      "Epoch 3, Step 0, Loss: 1.0030083656311035\n",
      "Epoch 4, Step 0, Loss: 0.9957859516143799\n",
      "Epoch 5, Step 0, Loss: 0.9894741177558899\n",
      "Epoch 6, Step 0, Loss: 0.9753241539001465\n",
      "Epoch 7, Step 0, Loss: 0.9937542676925659\n",
      "Epoch 8, Step 0, Loss: 0.817984938621521\n",
      "Epoch 9, Step 0, Loss: 0.9159425497055054\n",
      "Epoch 10, Step 0, Loss: 0.9225462675094604\n",
      "Epoch 11, Step 0, Loss: 0.922818660736084\n",
      "Epoch 12, Step 0, Loss: 1.0551756620407104\n",
      "Epoch 13, Step 0, Loss: 1.0166600942611694\n",
      "Epoch 14, Step 0, Loss: 0.8570143580436707\n",
      "Epoch 15, Step 0, Loss: 0.8706648349761963\n",
      "Epoch 16, Step 0, Loss: 0.7432109117507935\n",
      "Epoch 17, Step 0, Loss: 0.8500399589538574\n",
      "Epoch 18, Step 0, Loss: 0.942444920539856\n",
      "Epoch 19, Step 0, Loss: 0.6736522912979126\n",
      "Epoch 20, Step 0, Loss: 0.8385230898857117\n",
      "Epoch 21, Step 0, Loss: 0.8906406164169312\n",
      "Epoch 22, Step 0, Loss: 1.047188401222229\n",
      "Epoch 23, Step 0, Loss: 0.9801009893417358\n",
      "Epoch 24, Step 0, Loss: 0.8787898421287537\n",
      "Epoch 25, Step 0, Loss: 0.829564094543457\n",
      "Epoch 26, Step 0, Loss: 0.6927195191383362\n",
      "Epoch 27, Step 0, Loss: 0.7895157337188721\n",
      "Epoch 28, Step 0, Loss: 0.7530087828636169\n",
      "Epoch 29, Step 0, Loss: 0.8049353361129761\n",
      "Epoch 30, Step 0, Loss: 0.7463755011558533\n",
      "Epoch 31, Step 0, Loss: 0.9361810684204102\n",
      "Epoch 32, Step 0, Loss: 0.6759174466133118\n",
      "Epoch 33, Step 0, Loss: 0.9423314929008484\n",
      "Epoch 34, Step 0, Loss: 0.7110213041305542\n",
      "Epoch 35, Step 0, Loss: 0.7196334600448608\n",
      "Epoch 36, Step 0, Loss: 0.7326959371566772\n",
      "Epoch 37, Step 0, Loss: 0.7940316200256348\n",
      "Epoch 38, Step 0, Loss: 0.6815679669380188\n",
      "Epoch 39, Step 0, Loss: 0.8260999321937561\n",
      "Epoch 40, Step 0, Loss: 0.6605772972106934\n",
      "Epoch 41, Step 0, Loss: 0.8813901543617249\n",
      "Epoch 42, Step 0, Loss: 0.5777006149291992\n",
      "Epoch 43, Step 0, Loss: 0.8368102312088013\n",
      "Epoch 44, Step 0, Loss: 0.8339381217956543\n",
      "Epoch 45, Step 0, Loss: 0.8676096200942993\n",
      "Epoch 46, Step 0, Loss: 0.46744388341903687\n",
      "Epoch 47, Step 0, Loss: 0.7029168605804443\n",
      "Epoch 48, Step 0, Loss: 0.7320196032524109\n",
      "Epoch 49, Step 0, Loss: 0.8015055656433105\n",
      "Epoch 50, Step 0, Loss: 0.7136470079421997\n",
      "Epoch 51, Step 0, Loss: 0.7372620105743408\n",
      "Epoch 52, Step 0, Loss: 0.7750071883201599\n",
      "Epoch 53, Step 0, Loss: 0.7395074367523193\n",
      "Epoch 54, Step 0, Loss: 0.7281765937805176\n",
      "Epoch 55, Step 0, Loss: 0.694141149520874\n",
      "Epoch 56, Step 0, Loss: 0.6729559898376465\n",
      "Epoch 57, Step 0, Loss: 0.6676799654960632\n",
      "Epoch 58, Step 0, Loss: 0.6796053051948547\n",
      "Epoch 59, Step 0, Loss: 0.7834766507148743\n",
      "Epoch 60, Step 0, Loss: 0.6229074001312256\n",
      "Epoch 61, Step 0, Loss: 0.5841901302337646\n",
      "Epoch 62, Step 0, Loss: 0.5696808695793152\n",
      "Epoch 63, Step 0, Loss: 0.49064528942108154\n",
      "Epoch 64, Step 0, Loss: 0.8329273462295532\n",
      "Epoch 65, Step 0, Loss: 0.5377006530761719\n",
      "Epoch 66, Step 0, Loss: 0.804608166217804\n",
      "Epoch 67, Step 0, Loss: 0.7306239604949951\n",
      "Epoch 68, Step 0, Loss: 0.6825349926948547\n",
      "Epoch 69, Step 0, Loss: 0.739437460899353\n",
      "Epoch 70, Step 0, Loss: 0.7299824953079224\n",
      "Epoch 71, Step 0, Loss: 0.9386463165283203\n",
      "Epoch 72, Step 0, Loss: 0.6526638269424438\n",
      "Epoch 73, Step 0, Loss: 0.5814220309257507\n",
      "Epoch 74, Step 0, Loss: 0.5914614796638489\n",
      "Epoch 75, Step 0, Loss: 0.8277302980422974\n",
      "Epoch 76, Step 0, Loss: 0.7424806356430054\n",
      "Epoch 77, Step 0, Loss: 0.8475562930107117\n",
      "Epoch 78, Step 0, Loss: 0.8716044425964355\n",
      "Epoch 79, Step 0, Loss: 0.7449431419372559\n",
      "Epoch 80, Step 0, Loss: 0.4588089883327484\n",
      "Epoch 81, Step 0, Loss: 0.6114639043807983\n",
      "Epoch 82, Step 0, Loss: 0.7767597436904907\n",
      "Epoch 83, Step 0, Loss: 0.647452175617218\n",
      "Epoch 84, Step 0, Loss: 0.7804632186889648\n",
      "Epoch 85, Step 0, Loss: 0.5901890993118286\n",
      "Epoch 86, Step 0, Loss: 0.5855212807655334\n",
      "Epoch 87, Step 0, Loss: 0.6982336044311523\n",
      "Epoch 88, Step 0, Loss: 0.7794435024261475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Step 0, Loss: 0.6569786071777344\n",
      "Epoch 90, Step 0, Loss: 0.6663241982460022\n",
      "Epoch 91, Step 0, Loss: 0.5401999950408936\n",
      "Epoch 92, Step 0, Loss: 0.6070465445518494\n",
      "Epoch 93, Step 0, Loss: 0.7369554042816162\n",
      "Epoch 94, Step 0, Loss: 0.725275993347168\n",
      "Epoch 95, Step 0, Loss: 0.7392619848251343\n",
      "Epoch 96, Step 0, Loss: 0.5833296775817871\n",
      "Epoch 97, Step 0, Loss: 0.7352955341339111\n",
      "Epoch 98, Step 0, Loss: 0.6348308324813843\n",
      "Epoch 99, Step 0, Loss: 0.7088451385498047\n",
      "Epoch 100, Step 0, Loss: 0.5784915685653687\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, Input, Concatenate, GlobalAveragePooling1D, Normalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Load data\n",
    "whole_data = pd.read_excel('data/whole_data_cleaned.xlsx')\n",
    "whole_data.drop([\"website\",\"place_links\",\"description\"],axis=1,inplace=True)\n",
    "\n",
    "# Preprocess whole_data: Convert 'tags' from comma-separated strings to lists of integers\n",
    "def safe_int_convert(tag_list):\n",
    "    if isinstance(tag_list, list):\n",
    "        return tag_list\n",
    "    elif isinstance(tag_list, (int, float)):\n",
    "        return [int(tag_list)]\n",
    "    elif isinstance(tag_list, str):\n",
    "        try:\n",
    "            return list(map(int, tag_list.split(',')))\n",
    "        except ValueError:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "whole_data['tags'] = whole_data['tags'].apply(safe_int_convert)\n",
    "\n",
    "# Convert rating to float and handle any missing data\n",
    "whole_data['rating'] = whole_data['rating'].astype(float).fillna(whole_data['rating'].mean())\n",
    "\n",
    "# Drop unnecessary columns\n",
    "whole_data.drop('territory_id', axis=1, inplace=True)\n",
    "\n",
    "# Pad the sequences for tags\n",
    "tags_padded = pad_sequences(whole_data['tags'], padding='post')\n",
    "whole_data['tags'] = list(tags_padded)\n",
    "# Extract unique tags\n",
    "tags_flat = [tag for sublist in whole_data['tags'].tolist() for tag in sublist]\n",
    "unique_tags = np.unique(tags_flat)\n",
    "\n",
    "# Define the model\n",
    "def create_model(unique_tags, embedding_dim=64, dense_units=128):\n",
    "    # Tag embedding\n",
    "    tag_input = Input(shape=(None,), dtype=tf.int32, name='tags')\n",
    "    tag_lookup = tf.keras.layers.IntegerLookup(vocabulary=unique_tags, mask_token=None)\n",
    "    tag_embedding = Embedding(input_dim=len(unique_tags) + 1, output_dim=embedding_dim)\n",
    "    tag_embeddings = tag_embedding(tag_lookup(tag_input))\n",
    "    tag_embeddings = GlobalAveragePooling1D()(tag_embeddings)\n",
    "    \n",
    "    # Normalize rating\n",
    "    rating_input = Input(shape=(1,), dtype=tf.float32, name='rating')\n",
    "    rating_normalization = Normalization(axis=None)\n",
    "    \n",
    "    # Manually specify input shape\n",
    "    rating_normalization.build((None, 1))\n",
    "    \n",
    "    rating_normalized = rating_normalization(rating_input)\n",
    "    \n",
    "    # Concatenate all features\n",
    "    combined_embeddings = Concatenate()([\n",
    "        tag_embeddings,\n",
    "        rating_normalized\n",
    "    ])\n",
    "    \n",
    "    dense = Dense(dense_units, activation='relu')(combined_embeddings)\n",
    "    output = Dense(embedding_dim)(dense)\n",
    "    \n",
    "    model = Model(inputs=[tag_input, rating_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Adjusted hyperparameters\n",
    "model = create_model(unique_tags, embedding_dim=64, dense_units=128)\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    # Compute the distance between the anchor and the positive\n",
    "    positive_distance = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    \n",
    "    # Compute the distance between the anchor and the negative\n",
    "    negative_distance = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    \n",
    "    # Compute the triplet loss\n",
    "    loss = tf.maximum(positive_distance - negative_distance + margin, 0.0)\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "# Create a dataset for triplet loss training\n",
    "def generate_triplets(dataframe):\n",
    "    anchor_features = {\n",
    "        'tags': [],\n",
    "        'rating': []\n",
    "    }\n",
    "    positive_features = {\n",
    "        'tags': [],\n",
    "        'rating': []\n",
    "    }\n",
    "    negative_features = {\n",
    "        'tags': [],\n",
    "        'rating': []\n",
    "    }\n",
    "    \n",
    "    for _, row in dataframe.iterrows():\n",
    "        anchor_features['tags'].append(row['tags'])\n",
    "        anchor_features['rating'].append(row['rating'])\n",
    "        \n",
    "        positive_idx = np.random.choice(dataframe.index)\n",
    "        negative_idx = np.random.choice(dataframe.index)\n",
    "        \n",
    "        positive_row = dataframe.loc[positive_idx]\n",
    "        negative_row = dataframe.loc[negative_idx]\n",
    "        \n",
    "        positive_features['tags'].append(positive_row['tags'])\n",
    "        positive_features['rating'].append(positive_row['rating'])\n",
    "        \n",
    "        negative_features['tags'].append(negative_row['tags'])\n",
    "        negative_features['rating'].append(negative_row['rating'])\n",
    "    \n",
    "    return (\n",
    "        {k: pad_sequences(v, padding='post') if k == 'tags' else np.array(v) for k, v in anchor_features.items()},\n",
    "        {k: pad_sequences(v, padding='post') if k == 'tags' else np.array(v) for k, v in positive_features.items()},\n",
    "        {k: pad_sequences(v, padding='post') if k == 'tags' else np.array(v) for k, v in negative_features.items()}\n",
    "    )\n",
    "\n",
    "anchor_features, positive_features, negative_features = generate_triplets(whole_data)\n",
    "\n",
    "def triplet_generator(anchor_features, positive_features, negative_features, batch_size=32):\n",
    "    while True:\n",
    "        indices = np.arange(len(anchor_features['tags']))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        for start in range(0, len(anchor_features['tags']), batch_size):\n",
    "            end = start + batch_size\n",
    "            batch_indices = indices[start:end]\n",
    "            \n",
    "            anchor_batch = {k: v[batch_indices] for k, v in anchor_features.items()}\n",
    "            positive_batch = {k: v[batch_indices] for k, v in positive_features.items()}\n",
    "            negative_batch = {k: v[batch_indices] for k, v in negative_features.items()}\n",
    "            \n",
    "            yield (anchor_batch, positive_batch, negative_batch)\n",
    "\n",
    "batch_size = 32\n",
    "triplet_gen = triplet_generator(anchor_features, positive_features, negative_features, batch_size=batch_size)\n",
    "\n",
    "# Compile the model with custom training loop\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "@tf.function\n",
    "def train_step(anchor_batch, positive_batch, negative_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        anchor_embeddings = model(anchor_batch, training=True)\n",
    "        positive_embeddings = model(positive_batch, training=True)\n",
    "        negative_embeddings = model(negative_batch, training=True)\n",
    "        \n",
    "        loss = triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "steps_per_epoch = len(anchor_features['tags']) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step in range(steps_per_epoch):\n",
    "        anchor_batch, positive_batch, negative_batch = next(triplet_gen)\n",
    "        loss = train_step(anchor_batch, positive_batch, negative_batch)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Step {step}, Loss: {loss.numpy()}\")\n",
    "            \n",
    "# Save the trained model\n",
    "model.save('triplet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49cfaa77428e1afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T09:02:48.333826Z",
     "start_time": "2024-05-18T09:02:47.409836Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Recommended items: [ 58 159   6 114  96  90  69 166 174  85]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>tags</th>\n",
       "      <th>territory_id.1</th>\n",
       "      <th>locationYX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Historical Plane Tree of Çengelköy</td>\n",
       "      <td>4.3</td>\n",
       "      <td>[1, 2, 3, 12, 13, 14, 15]</td>\n",
       "      <td>1</td>\n",
       "      <td>41.05022883927636, 29.05278206286947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Sultanahmet Square</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1, 2, 3, 12, 13, 14, 15]</td>\n",
       "      <td>3</td>\n",
       "      <td>41.00640399569341, 28.976145898680326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagdat Avenue</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[13, 14, 15, 16, 17, 0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>40.9683886821237, 29.065833609170745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>French Street Cultural Center</td>\n",
       "      <td>4.2</td>\n",
       "      <td>[2, 13, 14, 15, 16, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>41.03218963326699, 28.979591696647134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ataturk Arboretum</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[9, 10, 11, 12, 13, 14, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>41.17686871834661, 28.985596773928652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Yıldız Park</td>\n",
       "      <td>4.7</td>\n",
       "      <td>[9, 10, 11, 12, 13, 14, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>41.04950796854129, 29.015295073702305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Kuzguncuk Icadiye Street</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[12, 13, 14, 15, 17, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>41.034480060651845, 29.030833399333115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Turkish and Islamic Arts Museum</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[2, 3, 4, 5, 6, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>41.01085761893604, 28.975403362743883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Istanbul Museum of the History of Science and ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>[2, 3, 4, 5, 6, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>41.0192882800712, 28.978594949501012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Yıldız Hamidiye Mosque</td>\n",
       "      <td>4.9</td>\n",
       "      <td>[1, 2, 3, 5, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>41.05168636373972, 29.009377384401752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  rating  \\\n",
       "58                  Historical Plane Tree of Çengelköy     4.3   \n",
       "159                                 Sultanahmet Square     4.6   \n",
       "6                                        Bagdat Avenue     4.6   \n",
       "114                      French Street Cultural Center     4.2   \n",
       "96                                   Ataturk Arboretum     4.6   \n",
       "90                                         Yıldız Park     4.7   \n",
       "69                            Kuzguncuk Icadiye Street     4.6   \n",
       "166                    Turkish and Islamic Arts Museum     4.6   \n",
       "174  Istanbul Museum of the History of Science and ...     4.4   \n",
       "85                              Yıldız Hamidiye Mosque     4.9   \n",
       "\n",
       "                           tags  territory_id.1  \\\n",
       "58    [1, 2, 3, 12, 13, 14, 15]               1   \n",
       "159   [1, 2, 3, 12, 13, 14, 15]               3   \n",
       "6    [13, 14, 15, 16, 17, 0, 0]               2   \n",
       "114   [2, 13, 14, 15, 16, 0, 0]               0   \n",
       "96   [9, 10, 11, 12, 13, 14, 0]               0   \n",
       "90   [9, 10, 11, 12, 13, 14, 0]               0   \n",
       "69   [12, 13, 14, 15, 17, 0, 0]               1   \n",
       "166       [2, 3, 4, 5, 6, 0, 0]               3   \n",
       "174       [2, 3, 4, 5, 6, 0, 0]               3   \n",
       "85        [1, 2, 3, 5, 0, 0, 0]               0   \n",
       "\n",
       "                                 locationYX  \n",
       "58     41.05022883927636, 29.05278206286947  \n",
       "159   41.00640399569341, 28.976145898680326  \n",
       "6      40.9683886821237, 29.065833609170745  \n",
       "114   41.03218963326699, 28.979591696647134  \n",
       "96    41.17686871834661, 28.985596773928652  \n",
       "90    41.04950796854129, 29.015295073702305  \n",
       "69   41.034480060651845, 29.030833399333115  \n",
       "166   41.01085761893604, 28.975403362743883  \n",
       "174    41.0192882800712, 28.978594949501012  \n",
       "85    41.05168636373972, 29.009377384401752  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('triplet_model.keras', custom_objects={'triplet_loss': triplet_loss})\n",
    "\n",
    "# Generate embeddings for all locations\n",
    "features = {\n",
    "    'tags': np.array(pad_sequences(whole_data['tags'], padding='post')),\n",
    "    'rating': np.array(whole_data['rating'])\n",
    "}\n",
    "location_embeddings = model.predict(features)\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(location_embeddings)\n",
    "\n",
    "# Function to generate recommendations for a specific place\n",
    "def recommend(input_features, k=20):\n",
    "    input_dict = {\n",
    "        'tags': tf.convert_to_tensor([input_features['tags']], dtype=tf.int32),\n",
    "        'rating': tf.convert_to_tensor([input_features['rating']], dtype=tf.float32)\n",
    "    }\n",
    "    \n",
    "    # Generate the query embedding\n",
    "    query_embedding = model.predict(input_dict)\n",
    "    location_embeddings = model.predict(features)\n",
    "    \n",
    "    # Compute cosine similarity between the query embedding and all location embeddings\n",
    "    similarities = cosine_similarity(query_embedding, location_embeddings)\n",
    "    \n",
    "    # Get the top-k most similar locations\n",
    "    top_k_indices = similarities[0].argsort()[-k:][::-1]\n",
    "    \n",
    "    return top_k_indices\n",
    "\n",
    "# Example usage\n",
    "input_features = {\n",
    "    'tags': [1,2,3,5],  # Example tags\n",
    "    'rating': 4.0\n",
    "}\n",
    "\n",
    "recommendations = recommend(input_features, k=10)\n",
    "print(\"Recommended items:\", recommendations)\n",
    "\n",
    "# Fetching the items from the dataset\n",
    "recommended_items = whole_data.iloc[recommendations]\n",
    "recommended_items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046f12d",
   "metadata": {},
   "source": [
    "# Collabrative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9a2dff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:23.219958Z",
     "start_time": "2024-05-17T19:26:20.352116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>place_id</th>\n",
       "      <th>continent</th>\n",
       "      <th>score</th>\n",
       "      <th>user_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>563837</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>776089</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>207024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>711495</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>463612</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>871687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>950867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>761356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>723599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1000</td>\n",
       "      <td>Male</td>\n",
       "      <td>227804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id user_gender  place_id  continent  score  user_age\n",
       "0           1        Male    563837          2      1        54\n",
       "1           1        Male    776089          2      0        54\n",
       "2           1        Male    207024          2      1        54\n",
       "3           1        Male    711495          2      1        54\n",
       "4           1        Male    463612          2      1        54\n",
       "...       ...         ...       ...        ...    ...       ...\n",
       "9995     1000        Male    871687          1      1        51\n",
       "9996     1000        Male    950867          1      1        51\n",
       "9997     1000        Male    761356          1      1        51\n",
       "9998     1000        Male    723599          1      1        51\n",
       "9999     1000        Male    227804          1      0        51\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load user data\n",
    "user_data = pd.read_excel('generated_user_data.xlsx')\n",
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9b06e390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:23.234958Z",
     "start_time": "2024-05-17T19:26:23.222960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>place_id</th>\n",
       "      <th>continent</th>\n",
       "      <th>score</th>\n",
       "      <th>user_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>563837</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>776089</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>207024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>711495</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>463612</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>733989</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>375467</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>992964</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>342528</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>459627</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id user_gender  place_id  continent  score  user_age\n",
       "0        1        Male    563837          2      1        54\n",
       "1        1        Male    776089          2      0        54\n",
       "2        1        Male    207024          2      1        54\n",
       "3        1        Male    711495          2      1        54\n",
       "4        1        Male    463612          2      1        54\n",
       "5        1        Male    733989          2      1        54\n",
       "6        1        Male    375467          2      1        54\n",
       "7        1        Male    992964          2      1        54\n",
       "8        1        Male    342528          2      1        54\n",
       "9        1        Male    459627          2      1        54"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[user_data['user_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a41bbd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:23.312478Z",
     "start_time": "2024-05-17T19:26:23.236960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess user_data\n",
    "user_data['user_id'] = user_data.index\n",
    "\n",
    "# Extract unique user_ids and place_ids\n",
    "unique_user_ids = user_data['user_id'].unique()\n",
    "unique_place_ids = user_data['place_id'].unique()\n",
    "\n",
    "# Create mappings for user_ids and place_ids\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(unique_user_ids)}\n",
    "place_id_to_index = {place_id: index for index, place_id in enumerate(unique_place_ids)}\n",
    "\n",
    "# Map user_ids and place_ids to indices\n",
    "user_data['user_index'] = user_data['user_id'].map(user_id_to_index)\n",
    "user_data['place_index'] = user_data['place_id'].map(place_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "404122a5ae8cd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:23.328481Z",
     "start_time": "2024-05-17T19:26:23.314477Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>place_id</th>\n",
       "      <th>continent</th>\n",
       "      <th>score</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_index</th>\n",
       "      <th>place_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>563837</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>776089</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>207024</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>711495</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>463612</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>Male</td>\n",
       "      <td>871687</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9995</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>Male</td>\n",
       "      <td>950867</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9996</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>Male</td>\n",
       "      <td>761356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9997</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>Male</td>\n",
       "      <td>723599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>9998</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>Male</td>\n",
       "      <td>227804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>9999</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id user_gender  place_id  continent  score  user_age  user_index  \\\n",
       "0           0        Male    563837          2      1        54           0   \n",
       "1           1        Male    776089          2      0        54           1   \n",
       "2           2        Male    207024          2      1        54           2   \n",
       "3           3        Male    711495          2      1        54           3   \n",
       "4           4        Male    463612          2      1        54           4   \n",
       "...       ...         ...       ...        ...    ...       ...         ...   \n",
       "9995     9995        Male    871687          1      1        51        9995   \n",
       "9996     9996        Male    950867          1      1        51        9996   \n",
       "9997     9997        Male    761356          1      1        51        9997   \n",
       "9998     9998        Male    723599          1      1        51        9998   \n",
       "9999     9999        Male    227804          1      0        51        9999   \n",
       "\n",
       "      place_index  \n",
       "0               0  \n",
       "1               1  \n",
       "2               2  \n",
       "3               3  \n",
       "4               4  \n",
       "...           ...  \n",
       "9995           72  \n",
       "9996           85  \n",
       "9997           64  \n",
       "9998          101  \n",
       "9999          153  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e75b4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:23.468012Z",
     "start_time": "2024-05-17T19:26:23.330481Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.src.layers import Multiply\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_ncf_model(num_users, num_places, embedding_dim=50, hidden_layers=[64, 32, 16, 8]):\n",
    "    # User input and embedding\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, name='user_embedding')(user_input)\n",
    "    user_embedding = Flatten()(user_embedding)\n",
    "    \n",
    "    # Place input and embedding\n",
    "    place_input = Input(shape=(1,), name='place_input')\n",
    "    place_embedding = Embedding(input_dim=num_places, output_dim=embedding_dim, name='place_embedding')(place_input)\n",
    "    place_embedding = Flatten()(place_embedding)\n",
    "    \n",
    "    # GMF part: element-wise product of user and place embeddings\n",
    "    gmf_vector = Multiply()([user_embedding, place_embedding])\n",
    "    \n",
    "    # MLP part: concatenate user and place embeddings\n",
    "    mlp_vector = Concatenate()([user_embedding, place_embedding])\n",
    "    \n",
    "    # Hidden layers for MLP\n",
    "    for units in hidden_layers:\n",
    "        mlp_vector = Dense(units, activation='relu')(mlp_vector)\n",
    "        \n",
    "    \n",
    "    # Concatenate GMF and MLP parts\n",
    "    combined_vector = Concatenate()([gmf_vector, mlp_vector])\n",
    "    \n",
    "    # Final prediction layer\n",
    "    output = Dense(1, activation='sigmoid')(combined_vector)\n",
    "    \n",
    "    # Build and compile model\n",
    "    model = Model(inputs=[user_input, place_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "num_users = len(unique_user_ids)\n",
    "num_places = len(unique_place_ids)\n",
    "embedding_dim = 50\n",
    "\n",
    "ncf_model = create_ncf_model(num_users, num_places, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fc7031f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:48.149969Z",
     "start_time": "2024-05-17T19:26:24.261568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 3s 5ms/step - loss: 0.4812 - accuracy: 0.8916 - val_loss: 0.3507 - val_accuracy: 0.8920\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2654 - accuracy: 0.8992 - val_loss: 0.3782 - val_accuracy: 0.8920\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.8347 - val_accuracy: 0.7545\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.2839e-05 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.7905\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.3727e-05 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.7840\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 1.3503e-05 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.7805\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 8.5378e-06 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.7780\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.8163e-06 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.7770\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1316e-06 - accuracy: 1.0000 - val_loss: 0.9873 - val_accuracy: 0.7755\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.0306e-06 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.7740\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 2.2789e-06 - accuracy: 1.0000 - val_loss: 1.0346 - val_accuracy: 0.7715\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.7492e-06 - accuracy: 1.0000 - val_loss: 1.0557 - val_accuracy: 0.7700\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.3653e-06 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.7685\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.0801e-06 - accuracy: 1.0000 - val_loss: 1.0962 - val_accuracy: 0.7665\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 8.6404e-07 - accuracy: 1.0000 - val_loss: 1.1146 - val_accuracy: 0.7650\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 6.9796e-07 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.7640\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 5.6863e-07 - accuracy: 1.0000 - val_loss: 1.1501 - val_accuracy: 0.7620\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 4.6659e-07 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.7605\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.8530e-07 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.7585\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1996e-07 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.7555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\batur\\OneDrive - Yildiz Technical University\\Okul\\3. Sinif\\YZUP\\Nokia Part Time Assignment\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "user_indices = user_data['user_index'].values\n",
    "place_indices = user_data['place_index'].values\n",
    "interactions = user_data['score'].values  # Assuming binary interaction (0 or 1)\n",
    "\n",
    "# Train the model\n",
    "ncf_model.fit(\n",
    "    x=[user_indices, place_indices],\n",
    "    y=interactions,\n",
    "    batch_size=32,\n",
    "    epochs=15,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Save the trained NCF model\n",
    "ncf_model.save('ncf_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "725d22d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:51.208487Z",
     "start_time": "2024-05-17T19:26:51.116484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "Recommended places for user: 10\n",
      "                                             name  rating  \\\n",
      "17                                  Moda Sea Club     4.8   \n",
      "28                               Hasanpasa Mosque     4.0   \n",
      "29                                      Dorock XL     3.5   \n",
      "89                                 Çırağan Palace     4.7   \n",
      "72                   Filizler Meatball Restaurant     4.0   \n",
      "94                                     Bebek Park     4.5   \n",
      "181  Venerable Patriarchal Church of Saint George     4.6   \n",
      "34                             Sekerci Cafer Erol     4.7   \n",
      "37                      Omer Faruk Toprak Library     4.6   \n",
      "176                          The Stone of Million     4.6   \n",
      "\n",
      "                         tags  territory_id.1  \\\n",
      "17   [13, 16, 17, 0, 0, 0, 0]               2   \n",
      "28      [1, 2, 3, 5, 0, 0, 0]               2   \n",
      "29     [15, 0, 0, 0, 0, 0, 0]               2   \n",
      "89      [1, 2, 3, 4, 7, 0, 0]               0   \n",
      "72     [13, 0, 0, 0, 0, 0, 0]               1   \n",
      "94    [9, 11, 12, 0, 0, 0, 0]               0   \n",
      "181     [1, 2, 3, 5, 0, 0, 0]               3   \n",
      "34     [14, 0, 0, 0, 0, 0, 0]               2   \n",
      "37      [8, 0, 0, 0, 0, 0, 0]               2   \n",
      "176     [1, 2, 3, 7, 0, 0, 0]               3   \n",
      "\n",
      "                                 locationYX  \n",
      "17    40.97906035376859, 29.023443808638966  \n",
      "28    40.99474202399425, 29.039204409442796  \n",
      "29   40.987474576709864, 29.025974810980422  \n",
      "89    41.04387308576512, 29.015929923862068  \n",
      "72     41.02255261847614, 29.00690662144621  \n",
      "94      41.0774968049039, 29.04858941093314  \n",
      "181  41.035408024332234, 28.951041573041618  \n",
      "34   40.990696769055376, 29.024770154139464  \n",
      "37    40.96463983879542, 29.094771508668305  \n",
      "176    41.0139843716984, 28.978576362840666  \n"
     ]
    }
   ],
   "source": [
    "def ncf_recommend(user_id, model, place_data, user_id_to_index, k=10):\n",
    "    user_index = user_id_to_index[user_id]\n",
    "    user_vector = np.full((len(place_data),), user_index)\n",
    "    place_indices = np.arange(len(place_data))\n",
    "    \n",
    "    # Predict scores for all places for the given user\n",
    "    predictions = model.predict([user_vector, place_indices])\n",
    "    top_k_indices = predictions.flatten().argsort()[-k:][::-1]\n",
    "    \n",
    "    # Get the recommended places\n",
    "    recommended_places = place_data.iloc[top_k_indices]\n",
    "    return recommended_places\n",
    "\n",
    "# Example usage\n",
    "user_id = 10  # Replace with the actual user_id\n",
    "recommended_places = ncf_recommend(user_id, ncf_model, whole_data, user_id_to_index, k=10)\n",
    "print(\"Recommended places for user:\", user_id)\n",
    "print(recommended_places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "92dc6d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:51.898861Z",
     "start_time": "2024-05-17T19:26:51.875847Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ncf_recommend() missing 1 required positional argument: 'user_id_to_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Replace with the actual user_id\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m recommended_places \u001b[38;5;241m=\u001b[39m \u001b[43mncf_recommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhole_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended places for user:\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_id)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommended_places)\n",
      "\u001b[1;31mTypeError\u001b[0m: ncf_recommend() missing 1 required positional argument: 'user_id_to_index'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_id = 10  # Replace with the actual user_id\n",
    "recommended_places = ncf_recommend(user_id, ncf_model, whole_data, k=10)\n",
    "print(\"Recommended places for user:\", user_id)\n",
    "print(recommended_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1eafae78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:52.755843Z",
     "start_time": "2024-05-17T19:26:52.744841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>place_id</th>\n",
       "      <th>continent</th>\n",
       "      <th>score</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_index</th>\n",
       "      <th>place_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>1231</td>\n",
       "      <td>Female</td>\n",
       "      <td>207141</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1231</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id user_gender  place_id  continent  score  user_age  user_index  \\\n",
       "1231     1231      Female    207141          4      1        53        1231   \n",
       "\n",
       "      place_index  \n",
       "1231          150  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data[user_data[\"user_id\"] == 1231]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed8543d6fa0fdc50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:53.545636Z",
     "start_time": "2024-05-17T19:26:53.529645Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [1, 2, 3, 4, 6, 7, 9, 11, 12, 13, 14, 15, 16], 'rating': 4.5}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cdc81b7a44b574d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:26:54.024447Z",
     "start_time": "2024-05-17T19:26:54.011435Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "59072009c827c7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:31:44.112853Z",
     "start_time": "2024-05-17T19:31:43.971802Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_features = {\n",
    "    'tags': [1, 2, 3, 4, 6, 7, 9, 11, 12, 13, 14, 15, 16],  # Example tags\n",
    "    'rating': 4.5\n",
    "}\n",
    "user_id = 0  # Replace with the actual user_id\n",
    "\n",
    "recommended_items = weighted_hybrid_recommend(input_features, user_id, model, ncf_model, whole_data, user_id_to_index, cb_weight=0, cf_weight=0.9, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "84b183047f3e777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:31:44.437147Z",
     "start_time": "2024-05-17T19:31:44.420147Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items for user: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended items for user:\", user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eda4e2488c180203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T19:31:44.838662Z",
     "start_time": "2024-05-17T19:31:44.831664Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     name  rating                       tags  \\\n",
      "187         Ruins of Philanthropos Church     4.5      [1, 2, 3, 5, 0, 0, 0]   \n",
      "58     Historical Plane Tree of Çengelköy     4.3  [1, 2, 3, 12, 13, 14, 15]   \n",
      "67                               KidZania     4.3    [18, 20, 0, 0, 0, 0, 0]   \n",
      "66      Emaar Aquarium and Underwater Zoo     4.3   [18, 20, 21, 0, 0, 0, 0]   \n",
      "65                    Small Camlica Grove     4.5   [9, 10, 11, 13, 0, 0, 0]   \n",
      "64                               Nevmekan     4.3     [13, 0, 0, 0, 0, 0, 0]   \n",
      "63            Historical Kuzguncuk Houses     4.7      [1, 2, 3, 7, 0, 0, 0]   \n",
      "62   Mahpeyker Kösem Valide Sultan Mosque     4.6      [1, 2, 3, 5, 0, 0, 0]   \n",
      "61                 Mihrimah Sultan Mosque     4.8      [1, 2, 3, 5, 0, 0, 0]   \n",
      "60          Mehmet Naci Akgöz Kite Museum     4.5      [4, 6, 0, 0, 0, 0, 0]   \n",
      "\n",
      "     territory_id.1                              locationYX  \n",
      "187               3   41.02291936064259, 28.984498453867523  \n",
      "58                1    41.05022883927636, 29.05278206286947  \n",
      "67                1  41.000639922916086, 29.055213157621235  \n",
      "66                1   41.00262778665512, 29.072372921916998  \n",
      "65                1  41.020454964073814, 29.064851103286273  \n",
      "64                1   41.02525737615866, 29.010374767967782  \n",
      "63                1  41.035635359473225, 29.029979104928746  \n",
      "62                1   41.01988706849905, 29.029304699004275  \n",
      "61                1   41.02687730617994, 29.016465244271846  \n",
      "60                1   41.02392981011595, 29.013201953741532  \n"
     ]
    }
   ],
   "source": [
    "print(recommended_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070accdfa72be4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
