{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Prepare TensorFlow dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Kadikoy Ferry Terminal'>, 'rating': <tf.Tensor: shape=(), dtype=float32, numpy=4.6>, 'territory_id': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'tags': <tf.Tensor: shape=(), dtype=string, numpy=b'1,9,14'>}\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "whole_data = pd.read_excel('data/whole_data_cleaned.xlsx')\n",
    "whole_data.drop([\"website\", \"place_links\", \"description\", \"territory_id.1\"], axis=1, inplace=True)\n",
    "\n",
    "# Convert tags to a comma-separated string, handling non-iterable values\n",
    "def convert_tags(x):\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return ','.join(map(str, x))\n",
    "    return str(x)\n",
    "\n",
    "whole_data['tags'] = whole_data['tags'].apply(convert_tags)\n",
    "\n",
    "# Ensure all columns are in the correct format\n",
    "whole_data['rating'] = whole_data['rating'].astype(np.float32)\n",
    "whole_data['territory_id'] = whole_data['territory_id'].astype(np.int64)  # Convert territory_id to float32\n",
    "\n",
    "# Convert the DataFrame to a TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    'name': whole_data['name'].values,\n",
    "    'rating': whole_data['rating'].values,\n",
    "    'territory_id': whole_data['territory_id'].values,\n",
    "    'tags': whole_data['tags'].values\n",
    "})\n",
    "\n",
    "# Display a sample of the dataset to verify the structure\n",
    "for element in dataset.take(1):\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask(embeddings, embeddings)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Instantiate and compile the model\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLocationAwareModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m))\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Shuffle and batch data for training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[72], line 31\u001b[0m, in \u001b[0;36mLocationAwareModel.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m candidate_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Modify the lambda function to use tf.gather\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m territory_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterritory_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m  \u001b[38;5;66;03m# Assuming territory_model contains embeddings\u001b[39;00m\n\u001b[0;32m     32\u001b[0m candidate_embeddings \u001b[38;5;241m=\u001b[39m candidate_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m name: tf\u001b[38;5;241m.\u001b[39mgather(territory_embeddings, name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterritory_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Metrics and Loss\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'embeddings'"
     ]
    }
   ],
   "source": [
    "class LocationAwareModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding for territory_id\n",
    "        self.territory_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(vocabulary=np.unique(whole_data['territory_id'])),\n",
    "            tf.keras.layers.Embedding(len(np.unique(whole_data['territory_id'])) + 1, 32)\n",
    "        ])\n",
    "\n",
    "        # Embedding for tags\n",
    "        self.tags_vectorizer = tf.keras.layers.TextVectorization(output_mode='int')\n",
    "        self.tags_vectorizer.adapt(whole_data['tags'])\n",
    "        self.tags_model = tf.keras.Sequential([\n",
    "            self.tags_vectorizer,\n",
    "            tf.keras.layers.Embedding(input_dim=self.tags_vectorizer.vocabulary_size(), output_dim=32),\n",
    "            tf.keras.layers.GlobalAveragePooling1D(),\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "\n",
    "        # Rating model\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Normalization(mean=np.mean(whole_data['rating']), variance=np.var(whole_data['rating'])),\n",
    "            tf.keras.layers.Dense(32, activation='relu')\n",
    "        ])\n",
    "\n",
    "        candidate_dataset = dataset.map(lambda x: x['name'])\n",
    "\n",
    "        # Modify the lambda function to use tf.gather\n",
    "        territory_embeddings = self.territory_model.embeddings  # Assuming territory_model contains embeddings\n",
    "        candidate_embeddings = candidate_dataset.map(\n",
    "            lambda name: tf.gather(territory_embeddings, name['territory_id'])\n",
    "        )\n",
    "\n",
    "        # Metrics and Loss\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=candidate_embeddings\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        territory_embeddings = self.territory_model(features['territory_id'])\n",
    "        tags_embeddings = self.tags_model(features['tags'])\n",
    "        rating_embeddings = self.rating_model(features['rating'])\n",
    "\n",
    "        # Combine embeddings\n",
    "        embeddings = tf.concat([territory_embeddings, tags_embeddings, rating_embeddings], axis=1)\n",
    "\n",
    "        return self.task(embeddings, embeddings)\n",
    "\n",
    "# Instantiate and compile the model\n",
    "model = LocationAwareModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Shuffle and batch data for training\n",
    "dataset = dataset.shuffle(10000).batch(128).cache()\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
